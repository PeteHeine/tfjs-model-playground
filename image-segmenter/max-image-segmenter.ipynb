{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAX + TF.js: Image Segmenter\n",
    "\n",
    "https://github.com/IBM/MAX-Image-Segmenter\n",
    "\n",
    "notes/links/etc\n",
    "\n",
    "- `Netron`: https://github.com/lutzroeder/Netron\n",
    "- `TF.js Converter`: https://github.com/tensorflow/tfjs-converter\n",
    "- `TF.js API`: https://js.tensorflow.org/api/latest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. [Prerequisites](#Prerequisites)\n",
    "1. [Print the graph nodes](#Print-the-graph-nodes)\n",
    "1. [Run inference using the graph](#Run-inference-using-the-graph)\n",
    "1. [Convert the model to a web-friendly format](#Convert-the-model-to-a-web-friendly-format)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Download and extract the model artifacts for the Image Segmenter:\n",
    "\n",
    "    [http://max-assets.s3-api.us-geo.objectstorage.softlayer.net/deeplab/deeplabv3_mnv2_pascal_trainval_2018_01_29.tar.gz](http://max-assets.s3-api.us-geo.objectstorage.softlayer.net/deeplab/deeplabv3_mnv2_pascal_trainval_2018_01_29.tar.gz)\n",
    "\n",
    "    For example, from a terminal window:\n",
    "    \n",
    "    ```\n",
    "    curl -O http://max-assets.s3-api.us-geo.objectstorage.softlayer.net/deeplab/deeplabv3_mnv2_pascal_trainval_2018_01_29.tar.gz\n",
    "\n",
    "    tar -zxvf deeplabv3_mnv2_pascal_trainval_2018_01_29.tar.gz\n",
    "    ```\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook has been tested with Python version 3.6.6\n",
    "!python --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook has been tested with tensorflow 1.12.0, tensorflowjs 0.8.0, and numpy 1.15.1\n",
    "!pip show tensorflow tensorflowjs numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install the packages needed\n",
    "\n",
    "# !pip install -Iv tensorflow\n",
    "# !pip install -Iv tensorflowjs\n",
    "# !pip install -Iv numpy\n",
    "\n",
    "# Restart the kernel after installation completes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<strong>NOTE</strong>: Update the variables with the appropriate directory path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # full path to extracted frozen graph\n",
    "frozen_graph_path = '/Users/va/Desktop/max/image-segmenter/model/frozen_inference_graph.pb'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "\n",
    "# Print the graph nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print('TF versions:', tf.GIT_VERSION, tf.VERSION)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Load the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the frozen file and parse it to get the unserialized graph_def\n",
    "def load_frozen_graph(graph_path):\n",
    "    with tf.gfile.GFile(graph_path, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        return graph_def\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load graph\n",
    "restored_graph_def = load_frozen_graph(frozen_graph_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Print graph nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print list graph nodes/tensors\n",
    "def list_nodes(graph_def):\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(\n",
    "            graph_def,\n",
    "            input_map=None,\n",
    "            return_elements=None,\n",
    "            name=\"\"\n",
    "        )\n",
    "\n",
    "    sess = tf.Session(graph=graph)\n",
    "    nodes = sess.graph.as_graph_def().node\n",
    "    print('graph has {} nodes \\r\\n'.format(len(nodes)))\n",
    "    \n",
    "    for n in nodes:\n",
    "        print(n.name + '=>' +  n.op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list graph nodes\n",
    "list_nodes(restored_graph_def)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "\n",
    "# Run inference using the graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<strong>NOTE</strong>: Update the variables with the appropriate path to an image to test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full path to a test image\n",
    "test_image_path = '/Users/va/Desktop/max/test/img-03.jpg'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Resize and display the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# value to resize image\n",
    "IMAGE_SIZE = 512\n",
    "\n",
    "# resizes an image\n",
    "def resize_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    width, height = image.size\n",
    "    resize_ratio = 1.0 * IMAGE_SIZE / max(width, height)\n",
    "    target_size = (int(resize_ratio * width), int(resize_ratio * height))\n",
    "    resized = image.convert('RGB').resize(target_size, Image.ANTIALIAS)\n",
    "\n",
    "    return resized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the image\n",
    "resized_image = resize_image(test_image_path)\n",
    "\n",
    "# display image\n",
    "resized_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Run prediction on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "INPUT_TENSOR_NAME = 'ImageTensor:0'\n",
    "OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'\n",
    "\n",
    "# runs prediction\n",
    "def run_inference(graph_def, image):\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(\n",
    "            graph_def,\n",
    "            input_map=None,\n",
    "            return_elements=None,\n",
    "            name=\"\"\n",
    "        )\n",
    "\n",
    "    sess = tf.Session(graph=graph)\n",
    "\n",
    "    batch_seg_map = sess.run(\n",
    "        OUTPUT_TENSOR_NAME,\n",
    "        feed_dict = { INPUT_TENSOR_NAME: [np.asarray(resized_image)] }\n",
    "    )\n",
    "    \n",
    "    return batch_seg_map[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run prediction\n",
    "seg_map = run_inference(restored_graph_def, resized_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Visualize the segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds color defined by the dataset colormap to the label\n",
    "def label_to_color_image(label):\n",
    "    if label.ndim != 2:\n",
    "        raise ValueError('Expect 2-D input label')\n",
    "\n",
    "    colormap = create_pascal_label_colormap()\n",
    "\n",
    "    if np.max(label) >= len(colormap):\n",
    "        raise ValueError('label value too large.')\n",
    "\n",
    "    return colormap[label]\n",
    "\n",
    "\n",
    "# creates a label colormap used in PASCAL VOC segmentation benchmark\n",
    "def create_pascal_label_colormap():\n",
    "    colormap = np.zeros((256, 3), dtype=int)\n",
    "    ind = np.arange(256, dtype=int)\n",
    "\n",
    "    for shift in reversed(range(8)):\n",
    "        for channel in range(3):\n",
    "            colormap[:, channel] |= ((ind >> channel) & 1) << shift\n",
    "        ind >>= 3\n",
    "\n",
    "    return colormap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map results to color\n",
    "seg_image = label_to_color_image(seg_map).astype(np.uint8)\n",
    "\n",
    "# display results\n",
    "Image.fromarray(seg_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "\n",
    "# Convert the model to a web-friendly format\n",
    "\n",
    "[https://github.com/tensorflow/tfjs-converter](https://github.com/tensorflow/tfjs-converter)\n",
    "\n",
    "\n",
    "```\n",
    "tensorflowjs_converter \\\n",
    "    --input_format=tf_frozen_model \\\n",
    "    --output_node_names='SemanticPredictions' \\\n",
    "    /path/to/frozen/model.pb \\\n",
    "    /path/to/web_asset_output_dir\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for tensorflowjs_converter\n",
    "!tensorflowjs_converter --version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<strong>NOTE</strong>: Update the variables with the appropriate graph output nodes and path to save the converted model assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the graph output nodes\n",
    "graph_output_nodes = 'SemanticPredictions'\n",
    "\n",
    "# set appropriate desired output path for web format\n",
    "web_asset_dir = '/Users/va/Desktop/max/image-segmenter/model-tfjs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "# create directory if it does not exist\n",
    "pathlib.Path(web_asset_dir).mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Run the converter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!tensorflowjs_converter \\\n",
    "    --input_format=tf_frozen_model \\\n",
    "    --output_node_names={graph_output_nodes} \\\n",
    "    {frozen_graph_path} \\\n",
    "    {web_asset_dir}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Print the converted model assets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "print(\"Web asset directory {}:\".format(web_asset_dir))\n",
    "\n",
    "web_assets = os.listdir(web_asset_dir)\n",
    "web_assets.sort()\n",
    "\n",
    "for file in web_assets:\n",
    "    file_stat = os.stat(\"{}/{}\".format(web_asset_dir,file))\n",
    "    print(\" {} {} {:>20}\".format(file.ljust(30), time.ctime(file_stat.st_mtime), file_stat.st_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
