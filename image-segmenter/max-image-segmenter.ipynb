{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM Code Model Asset Exchange Image Segmenter\n",
    "\n",
    "- https://github.com/IBM/MAX-Image-Segmenter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "1. In a terminal window, run the following commands to download and extract the model artifacts for the Image Segmenter:\n",
    "    ```\n",
    "    curl -O http://max-assets.s3-api.us-geo.objectstorage.softlayer.net/deeplab/deeplabv3_mnv2_pascal_trainval_2018_01_29.tar.gz\n",
    "    \n",
    "    tar -zxvf deeplabv3_mnv2_pascal_trainval_2018_01_29.tar.gz\n",
    "    ```    \n",
    "\n",
    "2. Run the notebook `jupyter notebook .`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook has been tested with Python version 3.6\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook has been tested with tensorflow 1.10.1, tensorflowjs 0.6.0, and numpy 1.14.5\n",
    "!pip show tensorflow tensorflowjs numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install the packages needed\n",
    "\n",
    "# !pip install -Iv tensorflow\n",
    "# !pip install -Iv tensorflowjs\n",
    "# !pip install -Iv numpy\n",
    "\n",
    "# Restart the kernel after installation completes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Update the variable with the appropriate directory path to extracted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full path to extracted frozen graph\n",
    "frozen_graph_path = '/Users/va/models/deeplabv3_mnv2_pascal_trainval_2018_01_29/frozen_inference_graph.pb'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Import libraries used in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TF versions:', tf.GIT_VERSION, tf.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "## Load frozen graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the frozen file and parse it to get the unserialized graph_def\n",
    "def load_frozen_graph(graph_path):\n",
    "    with tf.gfile.GFile(graph_path, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        return graph_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load graph\n",
    "restored_graph_def = load_frozen_graph(frozen_graph_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "## Inspect the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print list graph nodes/tensors\n",
    "def list_nodes(graph_def):\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(\n",
    "            restored_graph_def,\n",
    "            input_map=None,\n",
    "            return_elements=None,\n",
    "            name=\"\"\n",
    "        )\n",
    "\n",
    "    sess = tf.Session(graph=graph)\n",
    "    nodes = sess.graph.as_graph_def().node\n",
    "    print('graph has {} nodes \\r\\n'.format(len(nodes)))\n",
    "    \n",
    "    for n in nodes:\n",
    "        print(n.name + '=>' +  n.op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list graph nodes\n",
    "list_nodes(restored_graph_def)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "## Run inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Set the helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INPUT_TENSOR_NAME = 'ImageTensor:0'\n",
    "OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'\n",
    "# value to resize image\n",
    "IMAGE_SIZE = 512\n",
    "\n",
    "# resize the image\n",
    "def resize_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    width, height = image.size\n",
    "    resize_ratio = 1.0 * IMAGE_SIZE / max(width, height)\n",
    "    target_size = (int(resize_ratio * width), int(resize_ratio * height))\n",
    "    resized = image.convert('RGB').resize(target_size, Image.ANTIALIAS)\n",
    "\n",
    "    return resized\n",
    "\n",
    "\n",
    "# run prediction\n",
    "def run_inference(graph_def, image):\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(\n",
    "            restored_graph_def,\n",
    "            input_map=None,\n",
    "            return_elements=None,\n",
    "            name=\"\"\n",
    "        )\n",
    "\n",
    "    sess = tf.Session(graph=graph)\n",
    "\n",
    "    batch_seg_map = sess.run(\n",
    "        OUTPUT_TENSOR_NAME,\n",
    "        feed_dict = { INPUT_TENSOR_NAME: [np.asarray(resized_image)] }\n",
    "    )\n",
    "    \n",
    "    return batch_seg_map[0]\n",
    "\n",
    "\n",
    "# Creates a label colormap used in PASCAL VOC segmentation benchmark\n",
    "def create_pascal_label_colormap():\n",
    "    colormap = np.zeros((256, 3), dtype=int)\n",
    "    ind = np.arange(256, dtype=int)\n",
    "\n",
    "    for shift in reversed(range(8)):\n",
    "        for channel in range(3):\n",
    "            colormap[:, channel] |= ((ind >> channel) & 1) << shift\n",
    "        ind >>= 3\n",
    "\n",
    "    return colormap\n",
    "\n",
    "\n",
    "# Adds color defined by the dataset colormap to the label\n",
    "def label_to_color_image(label):\n",
    "    if label.ndim != 2:\n",
    "        raise ValueError('Expect 2-D input label')\n",
    "\n",
    "    colormap = create_pascal_label_colormap()\n",
    "\n",
    "    if np.max(label) >= len(colormap):\n",
    "        raise ValueError('label value too large.')\n",
    "\n",
    "    return colormap[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Set the path of the image to use and display the resized image. You can use any image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/va/models/stc.jpg'\n",
    "\n",
    "resized_image = resize_image(image_path)\n",
    "\n",
    "resized_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Run prediction for the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run prediction\n",
    "seg_map = run_inference(restored_graph_def, resized_image)\n",
    "print (seg_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Map individual segment results to a color and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# map results to color\n",
    "seg_image = label_to_color_image(seg_map).astype(np.uint8)\n",
    "\n",
    "# display results\n",
    "Image.fromarray(seg_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "\n",
    "# Converting to a web-friendly format\n",
    "\n",
    "[https://github.com/tensorflow/tfjs-converter](https://github.com/tensorflow/tfjs-converter)\n",
    "\n",
    "\n",
    "```\n",
    "tensorflowjs_converter \\\n",
    "    --input_format=tf_frozen_model \\\n",
    "    --output_node_names='SemanticPredictions' \\\n",
    "    /path/to/frozen/model.pb \\\n",
    "    /path/to/web_asset_output_dir\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full path to directory where converter output will be saved\n",
    "web_asset_dir = '/Users/va/models/web_assets'\n",
    "\n",
    "# create directory if it does not exist\n",
    "pathlib.Path(web_asset_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set appropriate frozen model path and desired output path for web format\n",
    "\n",
    "!tensorflowjs_converter \\\n",
    "    --input_format=tf_frozen_model \\\n",
    "    --output_node_names='SemanticPredictions' \\\n",
    "    {frozen_graph_path} \\\n",
    "    {web_asset_dir}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Web asset directory {}:\".format(web_asset_dir))\n",
    "\n",
    "web_assets = os.listdir(web_asset_dir)\n",
    "web_assets.sort()\n",
    "\n",
    "for file in web_assets:\n",
    "    file_stat = os.stat(\"{}/{}\".format(web_asset_dir,file))\n",
    "    print(\" {} {} {:>20}\".format(file.ljust(30), time.ctime(file_stat.st_mtime), file_stat.st_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
