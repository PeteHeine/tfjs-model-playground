{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAX + TF.js: Review Text Generator\n",
    "\n",
    "https://github.com/IBM/MAX-Review-Text-Generator\n",
    "\n",
    "notes/links/etc\n",
    "\n",
    "- `Netron`: https://github.com/lutzroeder/Netron\n",
    "- `TF.js Converter`: https://github.com/tensorflow/tfjs-converter\n",
    "- `TF.js API`: https://js.tensorflow.org/api/latest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. [Prerequisites](#Prerequisites)\n",
    "1. [Run inference using the model](#Run-inference-using-the-model)\n",
    "1. [Convert the model to a web-friendly format](#Convert-the-model-to-a-web-friendly-format)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Clone the MAX Review Text Generator GitHub repository:\n",
    "\n",
    "    ```\n",
    "    git clone https://github.com/IBM/MAX-Review-Text-Generator.git\n",
    "    ```\n",
    "\n",
    "- Download the model artifacts for the Review Text Generator:\n",
    "\n",
    "    [http://max-assets.s3-api.us-geo.objectstorage.softlayer.net/keras/generative_lang_model/generative_lang_model.h5](http://max-assets.s3-api.us-geo.objectstorage.softlayer.net/keras/generative_lang_model/generative_lang_model.h5)\n",
    "\n",
    "    For example, from a terminal window:\n",
    "    \n",
    "    ```\n",
    "    curl -O http://max-assets.s3-api.us-geo.objectstorage.softlayer.net/keras/generative_lang_model/generative_lang_model.h5\n",
    "    ```\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook has been tested with Python version 3.6.6\n",
    "!python --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook has been tested with tensorflow 1.12.0, tensorflowjs 0.8.0, and numpy 1.15.1\n",
    "!pip show tensorflow tensorflowjs numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install the packages needed\n",
    "\n",
    "# !pip install -Iv tensorflow\n",
    "# !pip install -Iv tensorflowjs\n",
    "# !pip install -Iv numpy\n",
    "\n",
    "# Restart the kernel after installation completes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<strong>NOTE</strong>: Update the variables with the appropriate directory path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full path to cloned repo\n",
    "review_text_generator = '/Users/va/Desktop/max/repos/MAX-Review-Text-Generator'\n",
    "\n",
    "# full path to extracted frozen graph\n",
    "keras_model_path = '/Users/va/Desktop/max/review-text-generator/model/generative_lang_model.h5'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "\n",
    "# Run inference using the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print('TF versions:', tf.GIT_VERSION, tf.VERSION)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Load Keras model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the keras model\n",
    "def load_keras_model(path):\n",
    "    model = tf.keras.models.load_model(\n",
    "        path,\n",
    "        custom_objects=None,\n",
    "        compile=True\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_keras_model(keras_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Load assets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# https://github.com/IBM/MAX-Review-Text-Generator/blob/master/core/backend.py#L28\n",
    "def load_assets(path):\n",
    "    p1 = '{}/char_indices.txt'.format(path)\n",
    "    print(p1)\n",
    "    with open(p1) as f:\n",
    "        char_indices = json.loads(f.read())\n",
    "        chars = sorted(char_indices.keys())\n",
    "        num_chars = len(chars)\n",
    "        \n",
    "    p2 = '{}/indices_char.txt'.format(path)\n",
    "    print(p2)\n",
    "    with open(p2) as f:\n",
    "        indices_char = json.loads(f.read())\n",
    "\n",
    "    return char_indices, chars, num_chars, indices_char\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the assets directory in the github repository\n",
    "model_assets = review_text_generator + '/assets'\n",
    "\n",
    "char_indices, chars, num_chars, indices_char = load_assets(model_assets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Run prediction on sample text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# length required for the seed text. \n",
    "# seed text will be padded or truncated as needed\n",
    "SEED_TEXT_LEN = 256\n",
    "\n",
    "\n",
    "# https://github.com/IBM/MAX-Review-Text-Generator/blob/master/core/backend.py#L45\n",
    "def predict(sentence, gen_chars=50):\n",
    "    # Generate text based on seed text.\n",
    "    sentence = sentence.lower()\n",
    "    for t, char in enumerate(sentence):\n",
    "        if char not in char_indices:\n",
    "            print(\"Bad char {} at position {}\".format(char, t))\n",
    "            raise ValueError(\n",
    "                    \"Unexpected character '{}' at position {}. \"\n",
    "                    \"Only lowercase ASCII characters, spaces, \"\n",
    "                    \"and basic punctuation are supported.\".format(char, t))\n",
    "\n",
    "    # The text passed into the model must be exactly SEED_TEXT_LEN\n",
    "    # characters long, or the model will crash. Pad or truncate.\n",
    "    if len(sentence) > SEED_TEXT_LEN:\n",
    "        sentence = sentence[:SEED_TEXT_LEN]\n",
    "    else:\n",
    "        sentence = sentence.rjust(SEED_TEXT_LEN)\n",
    "\n",
    "    generated = ''\n",
    "    start = timer()\n",
    "    \n",
    "    for i in range(gen_chars):\n",
    "        x = np.zeros((1, SEED_TEXT_LEN, num_chars))\n",
    "\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "\n",
    "        next_index = _sample(preds)\n",
    "        next_char = indices_char[str(next_index)]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "    \n",
    "    end = timer()\n",
    "    print('predict: {}'.format(end - start))\n",
    "\n",
    "    return generated\n",
    "\n",
    "\n",
    "# https://github.com/IBM/MAX-Review-Text-Generator/blob/master/core/backend.py#L36\n",
    "def _sample(preds, temperature=.6):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<strong>NOTE</strong>: Update the variables with the desired text to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence = 'Came here last Friday with my friends. Got there around 8:30 and got seated right away. Parking'\n",
    "sentence = 'heart be still i loved this place. way better than i expected. i had the spicy noodles and they were delicious, flavor great and quality was on point. for desert the sticky rice with mango, i dream about it now. highly recommend if you are in the mood for '\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run prediction\n",
    "# this may take a while\n",
    "generated = predict(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print orginial sentence plus generated text\n",
    "print (sentence + generated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "\n",
    "# Convert the model to a web-friendly format\n",
    "\n",
    "[https://github.com/tensorflow/tfjs-converter](https://github.com/tensorflow/tfjs-converter)\n",
    "\n",
    "\n",
    "```\n",
    "tensorflowjs_converter \\\n",
    "    --input_format=keras \\\n",
    "    /path/to/keras/model.h5 \\\n",
    "    /path/to/web_asset_output_dir\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for tensorflowjs_converter\n",
    "!tensorflowjs_converter --version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<strong>NOTE</strong>: Update the variables with the appropriate path to save the converted model assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set appropriate desired output path for web format\n",
    "web_asset_dir = '/Users/va/Desktop/max/review-text-generator/model-tfjs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "# create directory if it does not exist\n",
    "pathlib.Path(web_asset_dir).mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Run the converter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!tensorflowjs_converter \\\n",
    "    --input_format=keras \\\n",
    "    {keras_model_path} \\\n",
    "    {web_asset_dir}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Print the converted model assets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "print(\"Web asset directory {}:\".format(web_asset_dir))\n",
    "\n",
    "web_assets = os.listdir(web_asset_dir)\n",
    "web_assets.sort()\n",
    "\n",
    "for file in web_assets:\n",
    "    file_stat = os.stat(\"{}/{}\".format(web_asset_dir,file))\n",
    "    print(\" {} {} {:>20}\".format(file.ljust(30), time.ctime(file_stat.st_mtime), file_stat.st_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
